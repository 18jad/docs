---
title: 'Tracing'
metaTitle: 'Tracing (Preview)'
metaDescription: 'Diagnose application performance with detailed traces of each query.'
preview: true
tocDepth: 3
---

<TopBlock>

Prisma tracing logs
Prisma tracing outputs

Prisma tracing provides a detailed log of the activity that Prisma Client carries out, at an operation level, including the time taken to execute each query. It helps you analyze your application's performance and identify bottlenecks. Tracing is fully compliant with [OpenTelemetry](https://opentelemetry.io/), so you can use it as part of your end-to-end application tracing setup.

<Admonition type="info">

Tracing gives you a highly detailed, query-level insight into your Prisma project. If you want aggregated numerical reporting, such as query counts, connection counts, and total query execution times, see [Metrics](/concepts/components/prisma-client/metrics).

</Admonition>

</TopBlock>

## About tracing

When you enable tracing, Prisma Client writes out a trace for each request that it makes. **should we say operation here, rather than request**? Each trace includes one or more [spans](https://www.jaegertracing.io/docs/1.35/architecture/#span), each of which represents one stage in the request life-cycle (**check terminology here**), such as a database statement or command, or serialization and deserialization. Each span includes the round trip connection time from Prisma Client to the database and back.

**Maybe a diagram here to show:**

- Trace (Prisma operation)

  - Span (such as a connection)
  - Span (such as a database statement or command)
  - Span (such as deserialization)

  You can send tracing output to the console, or analyze it in any OpenTelemetry-compatible tracing system, such as [Jaeger](https://www.jaegertracing.io/).

**TBA: maybe a screenshot in Jaeger with example**

## Output

Depending on the Prisma operation (**request?**), Prisma Client might output any of the following spans:

- `prisma`: Represents the entire Prisma request, from Prisma Client to the database and back. It contains details such as the model and method called by the Prisma Client.
- `prisma:query_builder`: Represents how long the [Prisma engines](/concepts/components/prisma-engines) take to generate the SQL queries (**would it be more accurate to say "statement or command" instead of queries here? This is not running rhe command, is it? - it's building the query**). This includes deserialization of the Prisma Client request, validation, and transformation into SQL.
- `prisma:connection`: Represents how long it took for Prisma Client to get a database connection.
- `prisma:db_query`: Represents a SQL query that was executed against the database, the SQL statement or command (in the tags), and how long the query took to run.
- `prisma:itx_runner`: The start of an interactive transaction.
- `prisma:transaction`: The high-level transaction. **need more detail here - what do we mean by high-level?**

## Considerations and prerequisites

If your application sends a large number of spans that are sent to a [collector](https://opentelemetry.io/docs/collector/), this can have a performance impact. For recommended approaches to reduce this performance impact, see [Performance](#performance).

**is it correct to say that the user's application sends the spans to the collector?**

To use tracing, you must do the following:

1. [Install the appropriate dependencies](#step-1-install-up-to-date-prisma-dependencies).
1. [Enable the `tracing` feature flag in your Prisma schema file](#step-2-enable-the-feature-flag-in-your-prisma-schema-file).
1. [Configure OpenTelemetry](#step-3-configure-opentelemetry).

### Step 1. Install up-to-date Prisma dependencies

Use version `4.1.0` or higher of the `prisma`, `@prisma/client`, and '@prisma/instrumentation' npm packages.

```terminal
npm install prisma@latest --save-dev
npm install @prisma/client@latest --save
npm install @prisma/instrumentation --save
```

### Step 2: Enable the feature flag in your Prisma schema file

In the `generator` block of your `schema.prisma` file, enable the `tracing` feature flag:

```prisma
generator client {
  provider        = "prisma-client-js"
  previewFeatures = ["tracing"]
}
```

### Step 3: Configure OpenTelemetry

First, install the appropriate OpenTelemetry packages, as follows:

```console

$ npm install @opentelemetry/api @opentelemetry/context-async-hooks @opentelemetry/exporter-trace-otlp-http @opentelemetry/instrumentation @opentelemetry/resources @opentelemetry/sdk-trace-base @opentelemetry/semantic-conventions

```

Then, add the following to your application code:

```ts
import { registerInstrumentations } from '@opentelemetry/instrumentation'
import { PrismaInstrumentation } from '@prisma/instrumentation'

export function otelSetup() {
  registerInstrumentations({
    instrumentations: [new PrismaInstrumentation()],
  })
}
```

## Send tracing to the console

To send tracing to the console, add the following to you application code:

```ts
import { context } from '@opentelemetry/api'
import { AsyncHooksContextManager } from '@opentelemetry/context-async-hooks'
import { registerInstrumentations } from '@opentelemetry/instrumentation'
import { Resource } from '@opentelemetry/resources'
import {
  BasicTracerProvider,
  SimpleSpanProcessor,
  ConsoleSpanExporter,
} from '@opentelemetry/sdk-trace-base'
import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions'
import { PrismaInstrumentation } from '@prisma/instrumentation'
import { PrismaClient } from '@prisma/client'

const contextManager = new AsyncHooksContextManager().enable()

context.setGlobalContextManager(contextManager)

const provider = new BasicTracerProvider({
  resource: new Resource({
    [SemanticResourceAttributes.SERVICE_NAME]: 'test-tracing-service',
    [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',
  }),
})

// Console exporter
const consoleExporter = new ConsoleSpanExporter()
provider.addSpanProcessor(new SimpleSpanProcessor(consoleExporter))
provider.register()

// Register Prisma Instrumentation
registerInstrumentations({
  instrumentations: [new PrismaInstrumentation()],
})

async function main() {
  const prisma = new PrismaClient()

  const email = `user.${Date.now()}@prisma.io`

  await prisma.user.create({
    data: {
      email: email,
    },
  })
}

main()
...
```

## Send tracing to Jaeger

To send tracing to Jaeger, add the following to you application code:

```ts
import { context } from '@opentelemetry/api'
import { AsyncHooksContextManager } from '@opentelemetry/context-async-hooks'
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http'
import { registerInstrumentations } from '@opentelemetry/instrumentation'
import { Resource } from '@opentelemetry/resources'
import {
  BasicTracerProvider,
  SimpleSpanProcessor,
} from '@opentelemetry/sdk-trace-base'
import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions'
import { PrismaInstrumentation } from '@prisma/instrumentation'
import { PrismaClient } from '@prisma/client'

const contextManager = new AsyncHooksContextManager().enable()

context.setGlobalContextManager(contextManager)

const provider = new BasicTracerProvider({
  resource: new Resource({
    [SemanticResourceAttributes.SERVICE_NAME]: 'test-tracing-service',
    [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',
  }),
})

// Jaeger exporter
const otlpTraceExporter = new OTLPTraceExporter()
provider.addSpanProcessor(new SimpleSpanProcessor(otlpTraceExporter))
provider.register()

// Register Prisma Instrumentation
registerInstrumentations({
  instrumentations: [new PrismaInstrumentation()],
})

async function main() {
  const prisma = new PrismaClient()

  const email = `user.${Date.now()}@prisma.io`

  await prisma.user.create({
    data: {
      email: email,
    },
  })
}

main()
...
```

## Performance

If your application sends a large number of spans to a collector, this can have a performance impact. You can use the following approaches to reduce this impact.

**is it correct to say that the user's application sends the spans to the collector?**

### Use the BatchSpanProcessor

In a production environment, you can use the OpenTelemetry `BatchSpanProcessor` to send the spans to a collector in batches rather than one at a time. However, during development and testing, you might not want to send spans in batches. In this situation, you might prefer to use the `SimpleSpanProcessor`.

You can configure your application to use the appropriate span processor, depending on the environment, as follows:

```ts
import {
  SimpleSpanProcessor,
  BatchSpanProcessor,
} from '@opentelemetry/sdk-trace-base'

if (process.env.NODE_ENV === 'production') {
  provider.addSpanProcessor(new BatchSpanProcessor(otlpTraceExporter))
} else {
  provider.addSpanProcessor(new SimpleSpanProcessor(otlpTraceExporter))
}
```

### Send only a sample of the spans

Another way to avoid a performance penalty with tracing is to [use probability sampling](https://opentelemetry.io/docs/reference/specification/trace/tracestate-probability-sampling/) to send fewer spans to the collector. This reduces the collection cost of tracing but still gives a good representation of what is happening in your application.

An example implementation looks like this:

```ts
import { TraceIdRatioBasedSampler } from '@opentelemetry/core'

const provider = new BasicTracerProvider({
  sampler: new TraceIdRatioBasedSampler(0.1),
  resource: new Resource({
    // we can define some metadata about the trace resource
    [SemanticResourceAttributes.SERVICE_NAME]: 'test-tracing-service',
    [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',
  }),
})
```
