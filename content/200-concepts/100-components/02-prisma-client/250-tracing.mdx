---
title: 'Tracing'
metaTitle: 'Tracing (Preview)'
metaDescription: 'Diagnose application performance with detailed traces of each query.'
preview: true
tocDepth: 3
---

<TopBlock>

Prisma tracing provides a detailed log of the activity that Prisma Client carries out, at an operation level, including the time taken to execute each query. It helps you analyze your application's performance and identify bottlenecks. Tracing is fully compliant with [OpenTelemetry](https://opentelemetry.io/), so you can use it as part of your end-to-end application tracing setup.

<Admonition type="info">

Tracing gives you a highly detailed, operation-level insight into your Prisma project. If you want aggregated numerical reporting, such as query counts, connection counts, and total query execution times, see [Metrics](/concepts/components/prisma-client/metrics).

</Admonition>

</TopBlock>

## About tracing

When you enable tracing, Prisma Client generates a trace for each operation that it makes. Each trace is divided into one or more [spans](https://www.opentelemetry.io/docs/reference/specification/trace/api/#span). Each span represents the length of time that one stage of the operation takes, such as serialization, or a database query.

**Maybe a diagram here to show:**

Base diagram on this:
https://www.notion.so/prismaio/Consolidating-Tracing-9f801e655b154adf93d4fc0bc8f8337a#023638938c4f45348af7747ad5d0f336

- Trace (Prisma operation)

  - Span (such as a connection)
  - Span (such as a database statement or command)

  You can send tracing output to the console, or analyze it in any OpenTelemetry-compatible tracing system, such as [Jaeger](https://www.jaegertracing.io/), [Honeycomb](https://www.honeycomb.io/trace/) and [Datadog](https://www.datadoghq.com/). On this page, we give an example of how to send tracing to Jaeger, which you can [run locally](#run-jaeger-locally).

## Output

For each trace, Prisma Client outputs a series of spans. The number and type of these spans varies, depending on the Prisma operation. The possible span types are as follows:

- `prisma:transaction`: The [root span](https://opentelemetry.io/docs/concepts/observability-primer/#distributed-traces). This represents one Prisma operation.
  - `prisma`: Represents the entire Prisma request, from Prisma Client to the database and back. It contains details such as the model and method called by Prisma Client. Depending on the Prisme operation, it contains one or more of the following spans:
    - `prisma:query_builder`: Represents how long the [Prisma engines](/concepts/components/prisma-engines) take to generate the SQL queries. This includes deserialization of the Prisma Client request, validation, and transformation into SQL.
    - `prisma:connection`: Represents how long it took for Prisma Client to get a database connection.
    - `prisma:db_query`: Represents a SQL query that was executed against the database. It includes the SQL statement or command (in the tags), and how long the query took to run.
    - `prisma:itx_runner`: Represents the start of an interactive transaction.
    - `prisma:middleware`: Represents how long the operation spent in your [middleware](/concepts/components/prisma-client/middleware). By default, tracing does not output spans for middleware. To switch this feature on, see [Trace middleware](#trace-your-middleware).

### Output example

Consider the following operation:

```ts
await prisma.$transaction([
  prisma.user.create({
    data: {
      email: email,
    },
  }),
  prisma.user.findMany({
    where: {
      email: email,
    },
  }),
])
```

The trace is structured as follows:

- `prisma:transaction`
  - `prisma`: metadata about `create`
  - `prisma`:metadata about `findMany`
  - `prisma`
    - `prisma:query_builder`
    - `prisma:connection`
    - `prisma:db_query`: details of the first SQL query or command...
    - `prisma:db_query`: ...details of the next SQL query or command...
    - `prisma:db_query`: ...and so on, for each SQL query or command

## Considerations and prerequisites

If your application sends a large number of spans to a [collector](https://opentelemetry.io/docs/collector/), this can have a significant performance impact. For information on how to minimize this impact, see [Reduce performance impact](#reduce-performance-impact).

To use tracing, you must do the following:

1. [Install the appropriate dependencies](#step-1-install-up-to-date-prisma-dependencies).
1. [Enable the `tracing` feature flag in your Prisma schema file](#step-2-enable-the-feature-flag-in-your-prisma-schema-file).
1. [Configure OpenTelemetry](#step-3-configure-opentelemetry).

### Step 1. Install up-to-date Prisma dependencies

Use version `4.2.0` or higher of the `prisma`, `@prisma/client`, and `@prisma/instrumentation` npm packages.

```terminal
npm install prisma@latest --save-dev
npm install @prisma/client@latest --save
npm install @prisma/instrumentation --save
```

### Step 2: Enable the feature flag in your Prisma schema file

In the `generator` block of your `schema.prisma` file, enable the `tracing` feature flag:

```prisma
generator client {
  provider        = "prisma-client-js"
  previewFeatures = ["tracing"]
}
```

### Step 3: Configure OpenTelemetry

First, install the appropriate OpenTelemetry packages, as follows:

```console

$ npm install @opentelemetry/api @opentelemetry/context-async-hooks @opentelemetry/exporter-trace-otlp-http @opentelemetry/instrumentation @opentelemetry/resources @opentelemetry/sdk-trace-base @opentelemetry/semantic-conventions

```

## Output tracing to the console or an external tracing system

With the following code, you can write tracing to the console, or to an OpenTelemetry-compatible tracing system.

<Admonition type="info">

You can run some tracing systems locally. For an example of how to do this with Jaeger, see [Run Jaeger locally](#run-jaeger-locally).

</Admonition>

**For this code example, rather than provide a complete app, I think we need to just give the user some snippets of what to add to their app to 1. configure tracing in general, 2. send tracing to the console, and 3. send tracing to Jaeger. These should probably be separate headings**

```ts
import { Resource } from '@opentelemetry/resources'
import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions'
import {
  BasicTracerProvider,
  ConsoleSpanExporter,
  SimpleSpanProcessor,
} from '@opentelemetry/sdk-trace-base'
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http'
import { AsyncHooksContextManager } from '@opentelemetry/context-async-hooks'
import * as api from '@opentelemetry/api'
import { PrismaInstrumentation } from '@prisma/instrumentation'
import { registerInstrumentations } from '@opentelemetry/instrumentation'
import { trace } from '@opentelemetry/api'
import { PrismaClient } from '@prisma/client'
;/\*_ SETUP _/

export function otelSetup() {
  // a context manager is required to propagate the context
  const contextManager = new AsyncHooksContextManager().enable()

  // it's for Node.js for span nesting and ctx propagation
  api.context.setGlobalContextManager(contextManager)

  // a simple exporter that logs the raw data to the console
  const consoleExporter = new ConsoleSpanExporter()

  // exporter that works with Jaeger and other OpenTelemetry compliant collectors
  const otlpTraceExporter = new OTLPTraceExporter()

  // a standard provider that can run on the web and in Node.js
  const provider = new BasicTracerProvider({
    // sampler: new TraceIdRatioBasedSampler(0.1),
    resource: new Resource({
      // we can define some metadata about the trace resource
      [SemanticResourceAttributes.SERVICE_NAME]: 'sample-tracing-application',
      [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',
    }),
  })

  // send spans to the console
  provider.addSpanProcessor(new SimpleSpanProcessor(consoleExporter))
  // send spans to Jaeger or any OpenTelemetry compliant collector
  provider.addSpanProcessor(new SimpleSpanProcessor(otlpTraceExporter))

  provider.register()

  // Enable tracing in Prisma
  registerInstrumentations({
    instrumentations: [new PrismaInstrumentation()],
  })
}

//set up tracing for this application
otelSetup()

// set things up for tracing our application
const tracer = trace.getTracer('Example Application')

async function main() {
  const prisma = new PrismaClient()

  let users = await tracer.startActiveSpan('create-user', async (span) => {
    try {
      const email = `user.${Date.now()}@sample-application.com`
      await prisma.user.create({
        data: {
          email: email,
        },
      })
      let users = await prisma.user.findMany()
      return users
    } finally {
      span.end()
    }
  })

  console.table(users)
}

main().then(() => console.log('example complete'))
```

## Trace your middleware

To include your [middleware](/concepts/components/prisma-client/middleware) in your traces, set `middleware` to `true` in your `registerInstrumentations` statement:

```ts
registerInstrumentations({
  instrumentations: [new PrismaInstrumentation({ middleware: true })],
})
```

## Run Jaeger locally

To run Jaeger locally, use the following [Docker](https://www.docker.com/) command:

```console
docker run --rm --name jaeger \
  -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \
  -e COLLECTOR_OTLP_ENABLED=true \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 4317:4317 \
  -p 4318:4318 \
  -p 14250:14250 \
  -p 14268:14268 \
  -p 14269:14269 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.35
```

## Reduce performance impact

If your application sends a large number of spans to a collector, this can have a significant performance impact. You can use the following approaches to reduce this impact:

**Can we have a brief explanation as to how you quantify the performance impact/how you find out?**

- [Use the BatchSpanProcessor](#use-the-batchspanprocessor)
- [Send fewer spans to the collector](#send-fewer-spans-to-the-collector)

### Use the BatchSpanProcessor

In a production environment, you can use the OpenTelemetry `BatchSpanProcessor` to send the spans to a collector in batches rather than one at a time. However, during development and testing, you might not want to send spans in batches. In this situation, you might prefer to use the `SimpleSpanProcessor`.

You can configure your application to use the appropriate span processor, depending on the environment, as follows:

```ts
import {
  SimpleSpanProcessor,
  BatchSpanProcessor,
} from '@opentelemetry/sdk-trace-base'

if (process.env.NODE_ENV === 'production') {
  provider.addSpanProcessor(new BatchSpanProcessor(otlpTraceExporter))
} else {
  provider.addSpanProcessor(new SimpleSpanProcessor(otlpTraceExporter))
}
```

### Send fewer spans to the collector

Another way to reduce the performance impact is to [use probability sampling](https://opentelemetry.io/docs/reference/specification/trace/tracestate-probability-sampling/) to send fewer spans to the collector. This reduces the collection cost of tracing but still gives a good representation of what is happening in your application.

An example implementation looks like this:

```ts
import { TraceIdRatioBasedSampler } from '@opentelemetry/core'

const provider = new BasicTracerProvider({
  sampler: new TraceIdRatioBasedSampler(0.1),
  resource: new Resource({
    // we can define some metadata about the trace resource
    [SemanticResourceAttributes.SERVICE_NAME]: 'test-tracing-service',
    [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',
  }),
})
```
